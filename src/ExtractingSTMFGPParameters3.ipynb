{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "395d0c48-2f51-4ffe-aa1e-4784622ac314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch as gpt\n",
    "import botorch\n",
    "from botorch.models import SingleTaskMultiFidelityGP, SingleTaskGP\n",
    "from botorch.models.transforms.input import Normalize\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.fit import fit_gpytorch_mll, fit_gpytorch_mll_torch\n",
    "from torch.optim import Adam\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import HeBz\n",
    "import pickle\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Use CPU for this example\n",
    "device = torch.device(\"cuda\")\n",
    "dtype = torch.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d231053-9113-4c96-af10-e4b19a0778e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zpoints = np.linspace(0,7,100)\n",
    "xpoints = np.linspace(0,5,100)\n",
    "data_eval = []\n",
    "for i in range(100):\n",
    "    data_eval.append([4.5,0,zpoints[i],1.0])\n",
    "data_eval = np.array(data_eval)\n",
    "data_eval = torch.from_numpy(data_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f98c7e0-784b-470e-8448-05d0017ac7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the data from file\n",
    "V = np.load('../Final/HeBz_sector_2475.npy')\n",
    "x = np.array([])\n",
    "y = np.array([])\n",
    "z = np.array([])\n",
    "data_points = []\n",
    "Pot = np.array([])\n",
    "Pot_diff = np.array([])\n",
    "for array in V:\n",
    "    x = np.append(x,array[0])\n",
    "    y = np.append(y,array[1])\n",
    "    z = np.append(z,array[2])\n",
    "    data_points.append([array[0],array[1],array[2],1.0])\n",
    "    Pot = np.append(Pot,array[3])\n",
    "V2 = np.load('../Final/new_pts_70.npy')\n",
    "for array in V2:\n",
    "    x = np.append(x,array[0])\n",
    "    y = np.append(y,array[1])\n",
    "    z = np.append(z,array[2])\n",
    "    data_points.append([array[0],array[1],array[2],1.0])\n",
    "    Pot = np.append(Pot,array[3])\n",
    "data_points = np.array(data_points)\n",
    "noise = 1e-6*np.ones_like(Pot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "146a69df-586c-4c27-bbd0-089df1c89c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  0.00000000e+00  9.45945946e-02 ...  1.21158616e-08\n",
      "  -1.83603042e+04  1.00634447e+05]\n",
      " [ 0.00000000e+00  0.00000000e+00  8.51351351e-01 ... -2.11424265e-09\n",
      "  -8.68586691e+04  4.83971583e+04]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.60810811e+00 ...  3.99535650e-10\n",
      "  -2.31209156e+04  7.70900596e+03]\n",
      " ...\n",
      " [ 7.00000000e+00  0.00000000e+00  5.39189189e+00 ...  1.37187109e-11\n",
      "   4.48182311e-01  2.05744395e+00]\n",
      " [ 7.00000000e+00  0.00000000e+00  6.14864865e+00 ... -3.75382973e-11\n",
      "  -2.01439312e-01  2.36286681e+00]\n",
      " [ 7.00000000e+00  0.00000000e+00  6.90540541e+00 ...  9.38433445e-13\n",
      "   9.39158574e-02  2.36453566e+00]]\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 1. Generate Source Task Data\n",
    "# -----------------------------\n",
    "DFTdata0 = np.load(\"pbe0_113850_CP_D4_processed.npy\")\n",
    "ind = np.where(np.isclose(DFTdata0[:,2],0.09459459))\n",
    "refdata = DFTdata0[ind]\n",
    "refdata[:,2] = -1*refdata[:,2]\n",
    "DFTdata = np.concatenate((DFTdata0,refdata))\n",
    "ind = np.argsort(DFTdata[:,2], kind='stable')\n",
    "DFTdatazsrt = DFTdata[ind]\n",
    "ind = np.argsort(DFTdatazsrt[:,1], kind='stable')\n",
    "DFTdatayzsrt = DFTdatazsrt[ind]\n",
    "DFTdataxrem = DFTdatayzsrt[::8]\n",
    "ind = np.argsort(DFTdataxrem[:,0], kind='stable')\n",
    "DFTdataxremzsrt = DFTdataxrem[ind]\n",
    "DFTdatazxrem = DFTdataxremzsrt\n",
    "print(DFTdatazxrem)\n",
    "DFTdata2 = np.load(\"pbe0_corr_sutirtha_CP_D4_full_processed.npy\")\n",
    "#print(DFTdatazxrem)\n",
    "#print(np.min(DFTdata2[:,-1]))\n",
    "DFTdatanew = np.concatenate((DFTdata2[:,0],DFTdata2[:,1],DFTdata2[:,2]),)\n",
    "DFTtotal = np.concatenate((DFTdatazxrem[:,0:3],DFTdata2[:,0:3]))\n",
    "data_source = [[x, y, z, w] for x, y, z, w in zip(DFTtotal[:,0],DFTtotal[:,1],DFTtotal[:,2],np.zeros(len(DFTtotal)))]\n",
    "m_source = np.concatenate((DFTdatazxrem[:,-1],DFTdata2[:,-1]))\n",
    "noise_source = 1e-6*np.ones_like(m_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0818df3-f2d8-4880-a20b-debd5d838a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19506, 4)\n"
     ]
    }
   ],
   "source": [
    "train_X = np.concatenate((data_points,data_source))\n",
    "train_Y = np.concatenate((Pot,m_source))\n",
    "train_Y = train_Y.reshape(-1,1)\n",
    "train_Yvar = np.concatenate((noise,noise_source))\n",
    "train_Yvar = train_Yvar.reshape(-1,1)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd53f11-362a-4466-807d-ea7698aec2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18162, 4)\n"
     ]
    }
   ],
   "source": [
    "train_Y_trunc = train_Y[train_Y[:, 0]<=1000]\n",
    "train_Yvar_trunc = train_Yvar[train_Y[:,0]<=1000]\n",
    "train_X_trunc = train_X[train_Y[:, 0]<=1000, :]\n",
    "print(train_X_trunc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff4592a9-5478-4969-af66-483eaca111dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.6422]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('isaac/my_model_multfidDFT16kwNoiseRefBetter.pth')\n",
    "model = SingleTaskMultiFidelityGP(torch.from_numpy(train_X_trunc), torch.from_numpy(train_Y_trunc), torch.from_numpy(train_Yvar_trunc), data_fidelities=[len(train_X_trunc[0]) - 1], input_transform=Normalize(d=4),outcome_transform=Standardize(m=1))\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "958152c5-8f1d-418a-a12c-29fed35d38f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matern_kernel_np(x1, x2, lengthscale):\n",
    "    \"\"\"\n",
    "    Compute Matern kernel between x1 and x2 with given lengthscale and smoothness nu.\n",
    "    \"\"\"\n",
    "    # pairwise distance\n",
    "    r = cdist(x1 / lengthscale, x2 / lengthscale, metric='euclidean')\n",
    "    #print(r)\n",
    "    sqrt5 = np.sqrt(5.0)\n",
    "    k = (1 + sqrt5 * r + 5 * r**2 / 3) * np.exp(-sqrt5 * r)\n",
    "    return k\n",
    "def kernel_np(X1,X2,theta1,theta2,P,scale):\n",
    "    # split x and z\n",
    "    #print(X1,X2)\n",
    "    x1, z1 = X1[..., :-1], X1[..., -1:]\n",
    "    x2, z2 = X2[..., :-1], X2[..., -1:]\n",
    "    x11_ = z1\n",
    "    x21t_ = z2\n",
    "    x21t_ = np.transpose(x21t_)\n",
    "    #print(x11_,x21t_)\n",
    "    cross_term_1 = (1 - x11_) * (1 - x21t_)\n",
    "    bias_factor = cross_term_1 * np.power((1 + x11_ * x21t_),P)\n",
    "    #print(bias_factor)\n",
    "    return scale*(matern_kernel_np(x1,x2,lengthscale=theta1) + bias_factor*matern_kernel_np(x1,x2,lengthscale=theta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c881b23-b50e-494e-aad0-fa24feb51fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'mean_module.raw_constant': tensor(22.0553, dtype=torch.float64), 'covar_module.raw_outputscale': tensor(814.6966, dtype=torch.float64), 'covar_module.base_kernel.kernels.0.raw_power': tensor([-0.1112], dtype=torch.float64), 'covar_module.base_kernel.kernels.0.raw_power_constraint.lower_bound': tensor(0., dtype=torch.float64), 'covar_module.base_kernel.kernels.0.raw_power_constraint.upper_bound': tensor(inf, dtype=torch.float64), 'covar_module.base_kernel.kernels.0.power_prior.concentration': tensor(3., dtype=torch.float64), 'covar_module.base_kernel.kernels.0.power_prior.rate': tensor(3., dtype=torch.float64), 'covar_module.base_kernel.kernels.0.covar_module_unbiased.raw_lengthscale': tensor([[0.1785, 2.0518, 0.1523]], dtype=torch.float64), 'covar_module.base_kernel.kernels.0.covar_module_unbiased.lengthscale_prior.concentration': tensor(3., dtype=torch.float64), 'covar_module.base_kernel.kernels.0.covar_module_unbiased.lengthscale_prior.rate': tensor(6., dtype=torch.float64), 'covar_module.base_kernel.kernels.0.covar_module_unbiased.raw_lengthscale_constraint.lower_bound': tensor(0., dtype=torch.float64), 'covar_module.base_kernel.kernels.0.covar_module_unbiased.raw_lengthscale_constraint.upper_bound': tensor(inf, dtype=torch.float64), 'covar_module.base_kernel.kernels.0.covar_module_biased.raw_lengthscale': tensor([[1.8921, 5.0524, 1.5109]], dtype=torch.float64), 'covar_module.base_kernel.kernels.0.covar_module_biased.lengthscale_prior.concentration': tensor(6., dtype=torch.float64), 'covar_module.base_kernel.kernels.0.covar_module_biased.lengthscale_prior.rate': tensor(2., dtype=torch.float64), 'covar_module.base_kernel.kernels.0.covar_module_biased.raw_lengthscale_constraint.lower_bound': tensor(0., dtype=torch.float64), 'covar_module.base_kernel.kernels.0.covar_module_biased.raw_lengthscale_constraint.upper_bound': tensor(inf, dtype=torch.float64), 'covar_module.outputscale_prior.concentration': tensor(2., dtype=torch.float64), 'covar_module.outputscale_prior.rate': tensor(0.1500, dtype=torch.float64), 'covar_module.raw_outputscale_constraint.lower_bound': tensor(0., dtype=torch.float64), 'covar_module.raw_outputscale_constraint.upper_bound': tensor(inf, dtype=torch.float64), 'outcome_transform.means': tensor([[8.6422]], dtype=torch.float64), 'outcome_transform.stdvs': tensor([[104.9113]], dtype=torch.float64), 'outcome_transform._stdvs_sq': tensor([[11006.3882]], dtype=torch.float64), 'outcome_transform._is_trained': tensor(True), 'input_transform._coefficient': tensor([[7.0000, 3.5000, 7.0946, 1.0000]]), 'input_transform._offset': tensor([[ 0.0000,  0.0000, -0.0946,  0.0000]])})\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "02f742fc-fa7e-4b47-bc74-27e8ebe26672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6599, 0.5467, 0.5941, 1.0000],\n",
      "        [0.4949, 0.5714, 0.5941, 1.0000],\n",
      "        [0.4968, 0.2662, 0.5941, 1.0000],\n",
      "        ...,\n",
      "        [0.5939, 0.4920, 0.8647, 0.0000],\n",
      "        [0.5143, 0.0000, 0.8647, 0.0000],\n",
      "        [0.6429, 0.0000, 0.0133, 0.0000]], dtype=torch.float64)\n",
      "[[   9.19936053]\n",
      " [  29.38108591]\n",
      " [ -61.91943051]\n",
      " ...\n",
      " [   5.82816816]\n",
      " [ -34.95164383]\n",
      " [-200.36503508]]\n"
     ]
    }
   ],
   "source": [
    "ell1 = model.covar_module.base_kernel.kernels[0].covar_module_unbiased.lengthscale\n",
    "ell2 = model.covar_module.base_kernel.kernels[0].covar_module_unbiased.lengthscale\n",
    "p = model.covar_module.base_kernel.kernels[0].power\n",
    "oscale = model.covar_module.outputscale\n",
    "learned_mean = model.mean_module.constant\n",
    "train_x_trunc = torch.from_numpy(train_X_trunc)\n",
    "train_y_trunc = torch.from_numpy(train_Y_trunc)\n",
    "train_x_nrm = (train_x_trunc - torch.min(train_x_trunc,0)[0])/(torch.max(train_x_trunc,0)[0] -torch.min(train_x_trunc,0)[0])\n",
    "\n",
    "print(train_x_nrm)\n",
    "covar_matrix = model.covar_module(train_x_nrm,train_x_nrm).to_dense()\n",
    "covar_matrix = covar_matrix + model.likelihood.noise* torch.eye(covar_matrix.size(0))\n",
    "inverse_cov = torch.linalg.inv(covar_matrix)\n",
    "stdvs = train_y_trunc.std(dim=-2, keepdim=True)\n",
    "means = train_y_trunc.mean(dim=-2, keepdim=True)\n",
    "train_y_std = (train_y_trunc - means)/stdvs\n",
    "prod = torch.matmul(inverse_cov,train_y_std - learned_mean).to_dense().detach().numpy()   #Store this\n",
    "print(prod)\n",
    "prod2 = torch.linalg.solve(covar_matrix, train_y_std - learned_mean)\n",
    "#Store all parameters in a dictionary\n",
    "my_dict = {\n",
    "    \"outputscale\": model.covar_module.outputscale.detach().numpy(),\n",
    "    \"theta1\": model.covar_module.base_kernel.kernels[0].covar_module_unbiased.lengthscale.detach().numpy(),\n",
    "    \"theta2\":model.covar_module.base_kernel.kernels[0].covar_module_biased.lengthscale.detach().numpy(),\n",
    "    \"learned_mean\": model.mean_module.constant.detach().numpy(),\n",
    "    \"power\": model.covar_module.base_kernel.kernels[0].power.detach().numpy(),\n",
    "    \"data\":train_x_trunc.numpy(),\n",
    "    \"product\": prod,\n",
    "    \"stddevy\": stdvs.detach().numpy(),\n",
    "    \"meany\": means.detach().numpy()\n",
    "    \n",
    "}\n",
    "with open(\"data2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(my_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1ceef6d-19d1-4d65-8259-99eda67d71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    posterior_HF = model.posterior(torch.tensor([[4.5, 0., 6.718, 1.]]))\n",
    "    mean_HF = posterior_HF.mean.cpu().detach().numpy()\n",
    "    lower_HF, upper_HF = posterior_HF.confidence_region()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74309765-245b-4875-9d27-822ac4d1957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.         -0.09459459  0.        ]\n",
      "[7.  3.5 7.  1. ]\n",
      "[4.5        0.         6.71717172 1.        ]\n",
      "[[0.64285714 0.         0.96025143 1.        ]]\n",
      "tensor([[-9.4027]], dtype=torch.float64, grad_fn=<MulBackward0>) [[-8.83324499]]\n",
      "[-0.19109097]\n",
      "[array([[-0.84297114]])]\n",
      "[-0.84304046]\n"
     ]
    }
   ],
   "source": [
    "#Manual prediction\n",
    "with open('data2.pkl', 'rb') as file:\n",
    "    gp_data = pickle.load(file)\n",
    "#print(gp_data)\n",
    "predval = []\n",
    "newv = []\n",
    "tx = gp_data[\"data\"]\n",
    "print(np.min(tx,0))\n",
    "print(np.max(tx,0))\n",
    "tx_nrm = (tx - np.min(tx,0))/(np.max(tx,0) - np.min(tx,0))\n",
    "print(data_eval.numpy()[-5])\n",
    "for new in [[4.5, 0, 6.718, 1.]]:\n",
    "    new_nrm = (new - np.min(tx,0))/(np.max(tx,0) - np.min(tx,0))\n",
    "    new_nrm = new_nrm[np.newaxis,...]\n",
    "    print(new_nrm)\n",
    "    k = np.transpose(kernel_np(tx_nrm,new_nrm,gp_data['theta1'],gp_data['theta2'],gp_data['power'],gp_data['outputscale']))\n",
    "    k_ =  torch.transpose(model.covar_module(torch.from_numpy(tx_nrm),torch.from_numpy(new_nrm)).to_dense(),0,1)\n",
    "    new_val = learned_mean + k_ @ prod2\n",
    "    #print(gp_data[\"product\"],k)\n",
    "    evalz = gp_data['learned_mean'] + np.dot(k,gp_data[\"product\"])\n",
    "    print(new_val*104, evalz*104.9113)\n",
    "    newv.append(gp_data['meany'] + gp_data['stddevy']*new_val.detach().numpy())\n",
    "    predval.append(gp_data['meany'] + gp_data['stddevy']*evalz)\n",
    "predval = np.array(predval).flatten()\n",
    "\n",
    "print(predval)\n",
    "print(newv)\n",
    "print(mean_HF.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6aa999a-b1d5-4fbb-a990-963735a03170",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
